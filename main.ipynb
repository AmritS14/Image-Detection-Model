{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from coco_dataset import COCODetectionDataset\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set paths\n",
    "train_img_dir = 'data/coco_top10_2000/data'\n",
    "val_img_dir = 'data/coco_top10_2000/data'\n",
    "# train_ann_file = 'data/coco_top10_2000/labels.json'\n",
    "# val_ann_file = 'data/coco_top10_2000/labels.json'\n",
    "\n",
    "train_ann_file = 'data/coco_top10_2000/labels_balanced.json'\n",
    "val_ann_file = 'data/coco_top10_2000/labels_balanced.json'\n",
    "\n",
    "num_classes = 11  # 10 classes + 1 background\n",
    "num_epochs = 5\n",
    "batch_size = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def collateFn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainData = COCODetectionDataset(train_img_dir, train_ann_file, transforms=transform)\n",
    "valData = COCODetectionDataset(val_img_dir, val_ann_file, transforms=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collateFn)\n",
    "valLoader = DataLoader(valData, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=collateFn)\n",
    "\n",
    "print(f'Train samples: {len(trainData)}')\n",
    "print(f'Val samples: {len(valData)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def getModel(num_classes=11):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = getModel(num_classes)\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lrScheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in tqdm(trainLoader, desc=f'Epoch {i + 1}/{num_epochs}'):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        lossDIct = model(images, targets)\n",
    "        losses = sum(loss for loss in lossDIct.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += losses.item()\n",
    "    lrScheduler.step()\n",
    "    print(f'Epoch {i+1}, Loss: {running_loss/len(trainLoader):.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import traceback\n",
    "model.train()\n",
    "valLoss = 0.0\n",
    "numBatches = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, targets) in enumerate(tqdm(valLoader, desc='Validation')):\n",
    "        print(f\"Batch {i}: {[len(t['boxes']) for t in targets]}\")\n",
    "        skipBatch = False\n",
    "        for t in targets:\n",
    "            if len(t['boxes']) == 0 or len(t['boxes']) != len(t['labels']):\n",
    "                print(f\"Skipping batch {i} due to empty or mismatched targets\")\n",
    "                skipBatch = True\n",
    "                break\n",
    "        if skipBatch:\n",
    "            continue\n",
    "        try:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            lossDIct = model(images, targets)\n",
    "            losses = sum(loss for loss in lossDIct.values())\n",
    "            valLoss += losses.item()\n",
    "            numBatches += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            print(f\"Target boxes: {[t['boxes'].shape for t in targets]}\")\n",
    "            print(f\"Target labels: {[t['labels'].shape for t in targets]}\")\n",
    "            continue\n",
    "if numBatches > 0:\n",
    "    print(f'Validation Loss: {valLoss / numBatches:.4f}')\n",
    "else:\n",
    "    print(\"No valid batches in validation set!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "classNames = valData.class_names\n",
    "model.eval()\n",
    "img, _ = valData[random.randint(0, len(valData) - 1)]\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "scores = prediction[0]['scores'].cpu().numpy()\n",
    "labels = prediction[0]['labels'].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(transforms.ToPILImage()(img))\n",
    "for box, score, label in zip(boxes, scores, labels):\n",
    "    if score > 0.5:\n",
    "        x1, y1, x2, y2 = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2))\n",
    "        # label is 1-based, so subtract 1 for 0-based indexing\n",
    "        className = classNames[label - 1] if 1 <= label <= len(classNames) else 'unknown'\n",
    "        plt.text(x1, y1, f'{className}: {score:.2f}', color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Model saved as model.pth')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def loadModel(model_path, num_classes, device):\n",
    "    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "    import torchvision\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load model\n",
    "model_path = \"model.pth\"\n",
    "num_classes = 11  # 10 classes + background\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = loadModel(model_path, num_classes, device)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
